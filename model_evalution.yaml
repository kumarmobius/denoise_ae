name: Evaluate Denoising Autoencoder Model V2.3
inputs:
  - {name: trained_model, type: Model}
  - {name: test_dataset, type: Data}
  - {name: batch_size, type: Integer, optional: true, default: "32"}
  - {name: num_workers, type: Integer, optional: true, default: "0"}
  - {name: noise_type, type: String, optional: true, default: "gaussian"}
  - {name: noise_factor, type: Float, optional: true, default: "0.3"}
  - {name: compute_metrics, type: String, optional: true, default: "True"}
  - {name: seed, type: Integer, optional: true, default: "42"}

outputs:
  - {name: evaluation_results, type: Data}
  - {name: reconstruction_samples, type: Data}
  - {name: schema_json, type: String}

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v1
    command:
      - python3
      - -u
      - -c
      - |
        import argparse
        import os
        import sys
        import json
        import logging
        import random
        import time
        import numpy as np
        import torch
        import torch.nn as nn
        from torch.utils.data import DataLoader, TensorDataset
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

        logging.basicConfig(stream=sys.stdout, level=logging.INFO)
        logger = logging.getLogger("model_evaluator")

        parser = argparse.ArgumentParser()
        parser.add_argument('--trained_model', required=True)
        parser.add_argument('--test_dataset', required=True)
        parser.add_argument('--batch_size', type=int, default=32)
        parser.add_argument('--num_workers', type=int, default=0)
        parser.add_argument('--noise_type', type=str, default='gaussian')
        parser.add_argument('--noise_factor', type=float, default=0.3)
        parser.add_argument('--compute_metrics', type=lambda x: x.lower() == 'true', default=True)
        parser.add_argument('--seed', type=int, default=42)
        parser.add_argument('--evaluation_results', required=True)
        parser.add_argument('--reconstruction_samples', required=True)
        parser.add_argument('--schema_json', required=True)
        args = parser.parse_args()

        def ensure_dir_for(p):
            d = os.path.dirname(p)
            if d and not os.path.exists(d):
                os.makedirs(d, exist_ok=True)

        def set_seed(seed):
            random.seed(seed)
            np.random.seed(seed)
            torch.manual_seed(seed)
            torch.cuda.manual_seed(seed)
            torch.cuda.manual_seed_all(seed)
            torch.backends.cudnn.deterministic = True
            torch.backends.cudnn.benchmark = False
            logger.info(f"✓ Random seed set to: {seed}")

        def get_activation(activation_name):
            activations = {
                'relu': nn.ReLU(), 'leaky_relu': nn.LeakyReLU(0.2),
                'elu': nn.ELU(), 'selu': nn.SELU(), 'gelu': nn.GELU(),
                'tanh': nn.Tanh(), 'sigmoid': nn.Sigmoid(),
                'swish': nn.SiLU(), 'mish': nn.Mish(), 'prelu': nn.PReLU(),
            }
            return activations.get(activation_name.lower(), nn.ReLU())

        class Encoder(nn.Module):
            def __init__(self, input_dim, encoder_dims, latent_dim,
                         dropout, activation, use_batch_norm):
                super(Encoder, self).__init__()
                layers = []
                prev_dim = input_dim
                for idx, units in enumerate(encoder_dims):
                    layers.append(nn.Linear(prev_dim, units))
                    if use_batch_norm:
                        layers.append(nn.BatchNorm1d(units))
                    layers.append(get_activation(activation))
                    layers.append(nn.Dropout(dropout))
                    logger.info(f"    Encoder Layer {idx + 1}: {prev_dim} -> {units}")
                    prev_dim = units
                layers.append(nn.Linear(prev_dim, latent_dim))
                logger.info(f"    Encoder Latent : {prev_dim} -> {latent_dim}")
                self.encoder = nn.Sequential(*layers)

            def forward(self, x): return self.encoder(x)

        class Decoder(nn.Module):
            def __init__(self, latent_dim, decoder_dims, input_dim,
                         dropout, activation, use_batch_norm):
                super(Decoder, self).__init__()
                layers = []
                prev_dim = latent_dim
                for idx, units in enumerate(decoder_dims):
                    layers.append(nn.Linear(prev_dim, units))
                    if use_batch_norm:
                        layers.append(nn.BatchNorm1d(units))
                    layers.append(get_activation(activation))
                    layers.append(nn.Dropout(dropout))
                    logger.info(f"    Decoder Layer {idx + 1}: {prev_dim} -> {units}")
                    prev_dim = units
                layers.append(nn.Linear(prev_dim, input_dim))
                logger.info(f"    Decoder Output : {prev_dim} -> {input_dim}")
                self.decoder = nn.Sequential(*layers)

            def forward(self, z): return self.decoder(z)

        class DenoisingAutoencoder(nn.Module):
            def __init__(self, input_dim, encoder_dims, decoder_dims, latent_dim,
                         dropout, activation, use_batch_norm):
                super(DenoisingAutoencoder, self).__init__()
                self.input_dim  = input_dim
                self.latent_dim = latent_dim
                self.encoder = Encoder(input_dim, encoder_dims, latent_dim,
                                       dropout, activation, use_batch_norm)
                self.decoder = Decoder(latent_dim, decoder_dims, input_dim,
                                       dropout, activation, use_batch_norm)

            def forward(self, x):
                encoded = self.encoder(x)
                return self.decoder(encoded), encoded

            def encode(self, x): return self.encoder(x)
            def decode(self, z): return self.decoder(z)

        def add_noise_to_latent(latent_vectors, noise_type='gaussian', noise_factor=0.3):
            if noise_type == 'gaussian':
                return latent_vectors + torch.randn_like(latent_vectors) * noise_factor
            elif noise_type == 'salt_pepper':
                noisy = latent_vectors.clone()
                mask = torch.rand_like(latent_vectors) < noise_factor
                random_vals = torch.rand(mask.sum(), device=latent_vectors.device)
                random_vals = random_vals * (latent_vectors.max() - latent_vectors.min()) + latent_vectors.min()
                noisy[mask] = random_vals
                return noisy
            elif noise_type == 'dropout':
                return latent_vectors * (torch.rand_like(latent_vectors) > noise_factor)
            elif noise_type == 'uniform':
                return latent_vectors + (torch.rand_like(latent_vectors) - 0.5) * 2 * noise_factor
            else:
                raise ValueError(f"Unknown noise type: {noise_type}")

        def compute_reconstruction_metrics(original, reconstructed):
            o = original.cpu().numpy()
            r = reconstructed.cpu().numpy()
            metrics = {}
            metrics['mse']      = mean_squared_error(o.flatten(), r.flatten())
            metrics['rmse']     = np.sqrt(metrics['mse'])
            metrics['mae']      = mean_absolute_error(o.flatten(), r.flatten())
            metrics['r2_score'] = r2_score(o.flatten(), r.flatten())

            per_sample_mse = np.mean((o - r) ** 2, axis=1)
            metrics['mean_per_sample_mse'] = float(np.mean(per_sample_mse))
            metrics['std_per_sample_mse']  = float(np.std(per_sample_mse))
            metrics['min_per_sample_mse']  = float(np.min(per_sample_mse))
            metrics['max_per_sample_mse']  = float(np.max(per_sample_mse))

            from sklearn.metrics.pairwise import cosine_similarity
            cos_sim = [cosine_similarity(o[i:i+1], r[i:i+1])[0, 0] for i in range(len(o))]
            metrics['mean_cosine_similarity'] = float(np.mean(cos_sim))
            metrics['std_cosine_similarity']  = float(np.std(cos_sim))

            signal_power = np.mean(o ** 2)
            noise_power  = np.mean((o - r) ** 2)
            metrics['snr_db'] = float(10 * np.log10(signal_power / noise_power)) if noise_power > 0 else float('inf')
            return metrics

        def evaluate_model(model, dataloader, device, noise_type='gaussian', noise_factor=0.3):
            model.eval()
            all_originals, all_noisy, all_reconstructed, all_encoded = [], [], [], []
            with torch.no_grad():
                for (clean_latents,) in dataloader:
                    clean_latents = clean_latents.to(device)
                    noisy_latents = add_noise_to_latent(clean_latents, noise_type, noise_factor)
                    reconstructed, encoded = model(noisy_latents)
                    all_originals.append(clean_latents.cpu())
                    all_noisy.append(noisy_latents.cpu())
                    all_reconstructed.append(reconstructed.cpu())
                    all_encoded.append(encoded.cpu())
            return (torch.cat(all_originals, dim=0), torch.cat(all_noisy, dim=0),
                    torch.cat(all_reconstructed, dim=0), torch.cat(all_encoded, dim=0))

        try:
            set_seed(args.seed)

            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            if torch.cuda.is_available():
                logger.info(f"✓ GPU detected: {torch.cuda.get_device_name(0)}")
            else:
                logger.info("⚠ No GPU detected, using CPU")

            # ============================================
            # Load Trained Model checkpoint
            # ============================================
            logger.info("=" * 60)
            logger.info("Loading Trained Model")
            logger.info("=" * 60)

            model_checkpoint_path = os.path.join(args.trained_model, 'best_trained_model.pth')
            if not os.path.exists(model_checkpoint_path):
                raise FileNotFoundError(f"Trained model not found at: {model_checkpoint_path}")

            checkpoint = torch.load(model_checkpoint_path, map_location=device)
            logger.info(f"✓ Loaded trained model from: {model_checkpoint_path}")
            logger.info(f"  Epoch          : {checkpoint['epoch']}")
            logger.info(f"  Training loss  : {checkpoint['train_loss']:.6f}")
            logger.info(f"  Validation loss: {checkpoint['val_loss']:.6f}")

            # ============================================
            # ✅ Read model_config directly from checkpoint
            #    No need for init checkpoint at all
            # ============================================
            if 'model_config' not in checkpoint:
                raise KeyError(
                    "model_config not found in best_trained_model.pth. "
                    "Please retrain using the updated train YAML which saves "
                    "model_config inside the checkpoint."
                )

            model_config     = checkpoint['model_config']
            optimizer_config = checkpoint.get('optimizer_config', {})
            loss_type        = checkpoint.get('loss_type', 'mse')

            logger.info(f"✓ model_config loaded directly from checkpoint — no init file needed")
            logger.info(f"  input_dim      : {model_config['input_dim']}")
            logger.info(f"  encoder_dims   : {model_config['encoder_dims']}")
            logger.info(f"  decoder_dims   : {model_config['decoder_dims']}")
            logger.info(f"  latent_dim     : {model_config['latent_dim']}")
            logger.info(f"  activation     : {model_config.get('activation_function', 'relu')}")
            logger.info(f"  use_batch_norm : {model_config.get('use_batch_norm', True)}")
            logger.info(f"  dropout        : {model_config['dropout']}")

            # ============================================
            # Reconstruct Model
            # ============================================
            logger.info("=" * 60)
            logger.info("Reconstructing Model")
            logger.info("=" * 60)

            model = DenoisingAutoencoder(
                input_dim      = model_config['input_dim'],
                encoder_dims   = model_config['encoder_dims'],
                decoder_dims   = model_config['decoder_dims'],
                latent_dim     = model_config['latent_dim'],
                dropout        = model_config['dropout'],
                activation     = model_config.get('activation_function', 'relu'),
                use_batch_norm = model_config.get('use_batch_norm', True)
            )

            model.load_state_dict(checkpoint['model_state_dict'])
            model = model.to(device)
            model.eval()

            logger.info(f"✓ Model reconstructed and loaded to {device}")
            logger.info(f"  Total parameters : {sum(p.numel() for p in model.parameters()):,}")

            # ============================================
            # Load Test Dataset
            # ============================================
            logger.info("=" * 60)
            logger.info("Loading Test Dataset")
            logger.info("=" * 60)

            test_data       = torch.load(os.path.join(args.test_dataset, 'test_dataset.pt'), map_location='cpu')
            test_dataset    = TensorDataset(test_data)
            logger.info(f"✓ Loaded test dataset: {test_data.shape}")

            test_loader = DataLoader(test_dataset, batch_size=args.batch_size,
                                     shuffle=False, num_workers=args.num_workers,
                                     pin_memory=True if device == 'cuda' else False)
            logger.info(f"✓ Test batches  : {len(test_loader)}")
            logger.info(f"  Total samples : {len(test_dataset)}")

            # ============================================
            # Evaluate
            # ============================================
            logger.info("=" * 60)
            logger.info("Evaluating Model on Test Set")
            logger.info("=" * 60)
            logger.info(f"Noise type   : {args.noise_type}")
            logger.info(f"Noise factor : {args.noise_factor}")

            all_originals, all_noisy, all_reconstructed, all_encoded = evaluate_model(
                model=model, dataloader=test_loader, device=device,
                noise_type=args.noise_type, noise_factor=args.noise_factor
            )
            logger.info(f"✓ Evaluation complete — processed {len(all_originals)} samples")

            # ============================================
            # Compute Metrics
            # ============================================
            if args.compute_metrics:
                logger.info("=" * 60)
                logger.info("Computing Evaluation Metrics")
                logger.info("=" * 60)
                metrics = compute_reconstruction_metrics(all_originals, all_reconstructed)
                logger.info(f"  MSE                  : {metrics['mse']:.6f}")
                logger.info(f"  RMSE                 : {metrics['rmse']:.6f}")
                logger.info(f"  MAE                  : {metrics['mae']:.6f}")
                logger.info(f"  R² Score             : {metrics['r2_score']:.6f}")
                logger.info(f"  Mean Cosine Sim      : {metrics['mean_cosine_similarity']:.6f}")
                logger.info(f"  SNR (dB)             : {metrics['snr_db']:.2f}")
                logger.info(f"  Per-Sample MSE mean  : {metrics['mean_per_sample_mse']:.6f}")
                logger.info(f"  Per-Sample MSE std   : {metrics['std_per_sample_mse']:.6f}")
            else:
                metrics = {}

            # ============================================
            # Save Evaluation Results
            # ============================================
            os.makedirs(args.evaluation_results, exist_ok=True)
            evaluation_results = {
                'metrics': metrics,
                'test_samples': len(all_originals),
                'evaluation_config': {
                    'noise_type':   args.noise_type,
                    'noise_factor': args.noise_factor,
                    'batch_size':   args.batch_size
                },
                'model_info': {
                    'training_epoch':  int(checkpoint['epoch']),
                    'training_loss':   float(checkpoint['train_loss']),
                    'validation_loss': float(checkpoint['val_loss']),
                    'encoder_dims':    model_config['encoder_dims'],
                    'decoder_dims':    model_config['decoder_dims'],
                }
            }
            results_path = os.path.join(args.evaluation_results, 'evaluation_results.json')
            with open(results_path, 'w') as f:
                json.dump(evaluation_results, f, indent=2)
            logger.info(f"✓ Evaluation results saved to: {results_path}")

            with open(args.evaluation_results + ".meta.json", "w") as f:
                json.dump({"results_path": results_path, "test_samples": len(all_originals),
                           "mse": metrics.get('mse', 0.0)}, f, indent=2)

            # ============================================
            # Save Reconstruction Samples
            # ============================================
            os.makedirs(args.reconstruction_samples, exist_ok=True)
            num_samples_to_save = min(100, len(all_originals))
            samples_path = os.path.join(args.reconstruction_samples, 'reconstruction_samples.pt')
            torch.save({
                'original':      all_originals[:num_samples_to_save],
                'noisy':         all_noisy[:num_samples_to_save],
                'reconstructed': all_reconstructed[:num_samples_to_save],
                'encoded':       all_encoded[:num_samples_to_save]
            }, samples_path)
            logger.info(f"✓ Saved {num_samples_to_save} reconstruction samples")

            with open(args.reconstruction_samples + ".meta.json", "w") as f:
                json.dump({"samples_path": samples_path, "num_samples": num_samples_to_save}, f, indent=2)

            # ============================================
            # Save Schema JSON
            # ============================================
            current_timestamp = int(time.time())
            schema_data = {
                'timestamp': current_timestamp,
                'r2_score':  float(metrics.get('r2_score', 0.0) * 100),
                'mae':       float(metrics.get('mae',       0.0) * 100),
                'mse':       float(metrics.get('mse',       0.0) * 100),
                'rmse':      float(metrics.get('rmse',      0.0) * 100)
            }
            ensure_dir_for(args.schema_json)
            with open(args.schema_json, "w") as f:
                json.dump(schema_data, f, indent=2)
            logger.info(f"✓ Schema JSON saved to: {args.schema_json}")

            logger.info("=" * 60)
            logger.info("✓ Evaluation Complete!")
            logger.info("=" * 60)
            logger.info(f"Test MSE    : {metrics.get('mse',      0.0):.6f}")
            logger.info(f"Test RMSE   : {metrics.get('rmse',     0.0):.6f}")
            logger.info(f"R² Score    : {metrics.get('r2_score', 0.0):.6f}")

        except Exception as e:
            logger.exception(f"Fatal error during evaluation: {str(e)}")
            sys.exit(1)

    args:
      - --trained_model
      - {inputPath: trained_model}
      - --test_dataset
      - {inputPath: test_dataset}
      - --batch_size
      - {inputValue: batch_size}
      - --num_workers
      - {inputValue: num_workers}
      - --noise_type
      - {inputValue: noise_type}
      - --noise_factor
      - {inputValue: noise_factor}
      - --compute_metrics
      - {inputValue: compute_metrics}
      - --seed
      - {inputValue: seed}
      - --evaluation_results
      - {outputPath: evaluation_results}
      - --reconstruction_samples
      - {outputPath: reconstruction_samples}
      - --schema_json
      - {outputPath: schema_json}
